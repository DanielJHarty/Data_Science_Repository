{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will build a classification model to predict whether a policyholder will claim within a year. The response (target) variable will not be a continuous value like before (in Linear Regression), but rather a categorical one. \n",
    "\n",
    "The model we will consider here is called **Logistic Regression**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For classification, linear regression is not the right approach as it implies quantitative differences in classes, which may not be appropriate. Rather than modelling the response directly, logistic regression models the *probability* that the reponse belongs to a particular category. \n",
    "\n",
    "For example if we model the probability of a student score being above average, then we classify it as such if the probability is greater than a specific amount (i.e. we predict *above average* if $P(X) > T$, where $T$ is the threshold probability, usually 0.5 for a binary case)\n",
    "\n",
    "Since we are modelling the probability, $P(X)$ should be greater or equal to 0 and smaller or equal to 1 for it to make sense. We therefore require a function that gives outputs between 0 and 1 for all input values of $X$. For this we use the **logistic function** displayed graphical below:\n",
    "\n",
    "<img src=\"https://github.com/Samantha-movius/hello-world/blob/master/logistic_reg.png?raw=true\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "Which is defined by the function:\n",
    "\n",
    "$$P(X) = \\displaystyle \\frac{e^{\\beta_0 + \\beta_1 X}}{1+e^{\\beta_0 + \\beta_1 X}}$$\n",
    "\n",
    "After a bit of manipulation we arrive at:\n",
    "\n",
    "\\begin{align}\n",
    "1 - P(X) &= \\displaystyle \\frac{1}{1+e^{\\beta_0 + \\beta_1 X}} \\\\\n",
    "\\therefore \\log \\left( \\frac{P(X)}{1-P(X)} \\right) &= {\\beta_0 + \\beta_1 X}\n",
    "\\end{align}\n",
    "\n",
    "So the fraction on the left is being modelled as a linear function of the observations $X$, and this is known as the **log odds ratio**. Without the log sign in front of it, it is known simply as the odds ratio. While $P(X)$ is bounded between 0 and 1, the odds ratio is bounded between 0 and $\\infty$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some libraries we will need\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>steps</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>insurance_claim</th>\n",
       "      <th>claim_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>3009</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>yes</td>\n",
       "      <td>16884.9240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>3008</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>yes</td>\n",
       "      <td>1725.5523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3009</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>10009</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>8010</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>yes</td>\n",
       "      <td>3866.8552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  steps  children smoker     region insurance_claim  \\\n",
       "0   19  female  27.900   3009         0    yes  southwest             yes   \n",
       "1   18    male  33.770   3008         1     no  southeast             yes   \n",
       "2   28    male  33.000   3009         3     no  southeast              no   \n",
       "3   33    male  22.705  10009         0     no  northwest              no   \n",
       "4   32    male  28.880   8010         0     no  northwest             yes   \n",
       "\n",
       "   claim_amount  \n",
       "0    16884.9240  \n",
       "1     1725.5523  \n",
       "2        0.0000  \n",
       "3        0.0000  \n",
       "4     3866.8552  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data in and view first few entries\n",
    "df = pd.read_csv('claims_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by pre-processing the data so that we can run it through the algorithm. Just to recap, this involves:\n",
    "* Splitting the data into features and labels\n",
    "* Transforming the categorical features \n",
    "* Splitting the data into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lables\n",
    "y = df['insurance_claim']\n",
    "\n",
    "# Features\n",
    "X = df.drop(['insurance_claim', 'claim_amount'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the Features\n",
    "X_transformed = pd.get_dummies(X, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.2, random_state=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our data is ready. Let's train the logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import LogisticRegression from sklearn.linear_model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an instance of the `LogisticRegression()` object using the default parameters for now. In the following tutorial we'll look at varying one of the parameters in an attempt to improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `fit()` method to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is trained, we can extract the parameters. The parameters consist of the intercept and the coefficients related to the features. These parameters can be used to predict future claims given the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.6037659420897197"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.intercept_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.019738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>0.168708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>steps</th>\n",
       "      <td>-0.000137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>children</th>\n",
       "      <td>-1.256102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex_male</th>\n",
       "      <td>-0.012538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoker_yes</th>\n",
       "      <td>3.016435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_northwest</th>\n",
       "      <td>-0.510453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_southeast</th>\n",
       "      <td>-0.155735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_southwest</th>\n",
       "      <td>-0.157182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Coefficient\n",
       "age                  0.019738\n",
       "bmi                  0.168708\n",
       "steps               -0.000137\n",
       "children            -1.256102\n",
       "sex_male            -0.012538\n",
       "smoker_yes           3.016435\n",
       "region_northwest    -0.510453\n",
       "region_southeast    -0.155735\n",
       "region_southwest    -0.157182"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff_df = pd.DataFrame(lm.coef_.T,X_transformed.columns,columns=['Coefficient'])\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can you infer from the coefficients above?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting\n",
    "As we did before in Linear Regression, we use the predict function to obtain predictions from our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lm = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing the results we will look at two different metrics called **confusion matrix** and **classification report**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Confusion Matrix](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](https://github.com/Explore-AI/Public-Data/blob/master/Data/matrix2.png?raw=true)\n",
    "\n",
    "A confusion matrix is a table that is often used to describe the performance of a classification model (or \"classifier\") on a set of test data for which the true values are known, and the format of this is displayed in the image above. The confusion matrix itself is relatively simple to understand, but the related terminology can be confusing. (Thanks [DataSchool](http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/) for the help in explaining!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now define the most basic terms, which are whole numbers (not rates):\n",
    "\n",
    "* true positives (TP) : These are cases in which we predicted a claim, and they did indeed claim.\n",
    "* true negatives (TN) : We predicted no claim, and they did indeed not claim.\n",
    "* false positives (FP): We predicted claim, but they actually didn't claim (Also known as a **Type I error**).\n",
    "* false negatives (FN): We predicted no claim, but they actually claimed. (Also known as a **Type II error**).\n",
    "\n",
    "From the confusion matrix, we can determine the model **accuracy** as (TP+TN)/(TP+TN+FP+FN) which is the proportion of data  that was correctly classified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's import the `confusion_matrix` object to check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix takes in two arguments: the unseen y_test data as well as our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 97,  19],\n",
       "       [ 17, 135]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pred_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This doesn't look that nice, so we can put this matrix into a dataframe together with the appropriate labels to make it more clear which values relate to which metric. The matrix works alphabetically, so the first row/column refers to 'no' claim since  it comes before 'yes' alphabetically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No claim</th>\n",
       "      <th>Claim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No claim</th>\n",
       "      <td>97</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Claim</th>\n",
       "      <td>17</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          No claim  Claim\n",
       "No claim        97     19\n",
       "Claim           17    135"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['No claim', 'Claim']\n",
    "\n",
    "pd.DataFrame(data=confusion_matrix(y_test, pred_lm), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better. The rows represent the actual output, while the columns indicate the predicted output. We see that we have classified 97+135=233 claims correctly, and 17+19=36 claims incorrectly.\n",
    "\n",
    "#### [Classification reports](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Classification Report gives us more information on where our model is going wrong - looking specifically at the performance caused by Type I & II errors.  The following metrics are calculated as part of the classification report. \n",
    "* Precision: When it predicts yes, how often is it correct? \n",
    "\n",
    "$ Precision = \\frac{True Positive}{Predicted Positive} $\n",
    "\n",
    "* Recall: When the outcome is actually True, how often do we predict it so?\n",
    "\n",
    "$ Recall = \\frac{True Positive}{Condition True}$\n",
    "\n",
    "* [F1 score](https://en.wikipedia.org/wiki/F1_score): = weighted average of Precision and Recall. \n",
    "\n",
    "$F_1 = 2 \\times \\frac {precision \\times recall }{precision + recall }$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's import the `classification_report` object to check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to the confusion matrix, the classification matrix takes in two arguments: the unseen y_test data as well as our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No claim       0.85      0.84      0.84       116\n",
      "       Claim       0.88      0.89      0.88       152\n",
      "\n",
      "    accuracy                           0.87       268\n",
      "   macro avg       0.86      0.86      0.86       268\n",
      "weighted avg       0.87      0.87      0.87       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification Report')\n",
    "print(classification_report(y_test, pred_lm, target_names=['No claim', 'Claim']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our accuracy is 87%, which is good. Can we improve this number? And what can we do to try and improve it? In the next tutorial we will look at ways to increase the accuracy and select the best model. \n",
    "\n",
    "Before we move on to this, let's consider the advantages and disadvantages of logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advantages & Disadvantages of Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advantages**\n",
    "\n",
    "* Convenient probability scores for observations (probability of each outcome is transformed into a classification)\n",
    "* Not a major issue if there are dependance between features (much worse with linear regression)\n",
    "\n",
    "**Disadvantages**\n",
    "\n",
    "* Can overfit when data is unbalanced (i.e. one label category dominates)\n",
    "* Doesn't handle large number of categorical features/variables well"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
